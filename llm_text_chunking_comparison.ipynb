{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1.2: Foundations of AI Quiz\n",
    "\n",
    "This notebook contains 20 multiple-choice questions covering fundamental concepts in AI and Machine Learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Which conclusion most accurately aligns with the implications of the No Free Lunch theorem in machine learning?\n",
    "\n",
    "A. Every algorithm achieves optimal performance given sufficient training data.  \n",
    "B. Model performance generalizes across tasks if architecture complexity is high.  \n",
    "C. No algorithm is universally superior; performance depends entirely on problem-specific data and assumptions.  \n",
    "D. Complex algorithms like deep neural networks outperform traditional models in all contexts.\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** There is no one-size-fits-all algorithm—each method's success depends on matching its inductive biases to the specific problem and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Which statement best describes the relationship between AI and machine learning (ML)?\n",
    "\n",
    "A. AI is the broad field of building intelligent systems; ML is the core set of algorithms that enable those systems to learn from data.  \n",
    "B. ML is a subset of AI that only uses neural networks.  \n",
    "C. AI and ML are synonymous and interchangeable terms.  \n",
    "D. ML refers only to data preprocessing, while AI refers to model building.\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** AI encompasses all approaches to creating intelligent behavior; ML specifically refers to the data-driven learning methods at its core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Which mathematical formulation is most commonly minimized in supervised regression tasks?\n",
    "\n",
    "A. Sum of absolute differences between predictions and targets  \n",
    "B. Cross-entropy between predicted and true class distributions  \n",
    "C. Sum of squared errors between predictions and targets  \n",
    "D. Hinge loss over margin violations\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** The least-squares criterion—minimizing sum of squared errors—has been the foundational regression loss since Gauss and Legendre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What does the difference between the model's prediction $\\hat{y}$ and the ground truth $y$ represent?\n",
    "\n",
    "A. Bias  \n",
    "B. Noise  \n",
    "C. Loss  \n",
    "D. Activation\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** $\\hat{y} - y$ quantifies the model's error on a single example, forming the basis for the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Why is the error term squared in the Mean Squared Error (MSE) loss function?\n",
    "\n",
    "A. To make the error positive and penalize larger errors more  \n",
    "B. To normalize the error over data points  \n",
    "C. To avoid bias in predictions  \n",
    "D. To satisfy gradient-descent assumptions\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** Squaring ensures positivity and disproportionately penalizes larger deviations, improving sensitivity to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "What does the neural network training process fundamentally aim to minimize?\n",
    "\n",
    "A. The number of neurons  \n",
    "B. The difference between activation and input  \n",
    "C. The loss function  \n",
    "D. The gradient direction\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** Training adjusts weights via gradient-based optimization to minimize aggregate prediction error (the loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "What does the Universal Approximation Theorem claim about neural networks?\n",
    "\n",
    "A. They can exactly recover ground truth for any dataset  \n",
    "B. They are always better than traditional models  \n",
    "C. A single-hidden-layer network can approximate any continuous function given sufficient neurons  \n",
    "D. They require multiple layers to approximate any function\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** Even one hidden layer with enough units can approximate any continuous function on a compact domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "What role does the activation function play in a neural network?\n",
    "\n",
    "A. It normalizes inputs  \n",
    "B. It adds linearity to the model  \n",
    "C. It introduces non-linearity to allow learning complex relationships  \n",
    "D. It reduces the model's capacity\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** Non-linear activations (ReLU, tanh, sigmoid) enable networks to model complex, non-linear mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "Why is the term \"regression\" historically used in predictive modeling?\n",
    "\n",
    "A. Because models regress in performance over time  \n",
    "B. Due to the phenomenon of regression toward the mean observed by Galton  \n",
    "C. Because it implies non-linear prediction  \n",
    "D. It refers to a type of regularization\n",
    "\n",
    "**Answer: B**\n",
    "\n",
    "**Rationale:** Galton observed that quantitative traits tend to regress toward the population average, inspiring the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Which of the following is not typically a purpose of the loss function?\n",
    "\n",
    "A. Measuring prediction accuracy  \n",
    "B. Guiding parameter updates  \n",
    "C. Ensuring binary classification  \n",
    "D. Quantifying model error\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** Loss functions quantify error and guide learning; classification type is determined by model/output design, not the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "What is the primary function of a neuron in a neural network?\n",
    "\n",
    "A. To perform a linear transformation followed by a nonlinear transformation  \n",
    "B. To store data for future use  \n",
    "C. To execute complex mathematical operations  \n",
    "D. To transmit data between different networks\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** A neuron computes a weighted sum plus bias (linear) then applies a nonlinear activation, enabling complex function approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "What is the main reason for using a sigmoid activation function?\n",
    "\n",
    "A. To introduce nonlinearity into the model  \n",
    "B. To ensure the model is always accurate  \n",
    "C. To simplify computation  \n",
    "D. To increase processing speed\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** Sigmoid squashes outputs to [0,1] and introduces nonlinearity—critical for learning complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "What is the primary purpose of the loss function in machine learning?\n",
    "\n",
    "A. To quantify the error between predicted and actual values  \n",
    "B. To increase the speed of the learning process  \n",
    "C. To store data for future reference  \n",
    "D. To ensure the model is always correct\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** The loss provides a scalar measure of error that guides parameter updates via backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "What does the term 'regression' refer to in ML?\n",
    "\n",
    "A. A model that predicts a continuous number  \n",
    "B. A model that classifies data  \n",
    "C. A model that reduces data size  \n",
    "D. A model that increases prediction accuracy\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** Regression predicts continuous outcomes (e.g., price, temperature), unlike classification's discrete labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "\n",
    "What type of activation function behaves like an electronic diode (output = input if positive, else zero)?\n",
    "\n",
    "A. ReLU  \n",
    "B. Tanh  \n",
    "C. GELU  \n",
    "D. ELU\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** ReLU(x) = max(0, x) is computationally simple and mitigates the vanishing gradient for positive values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "\n",
    "How did reinforcement learning contribute to AlphaFold's success?\n",
    "\n",
    "A. It directly classified protein types  \n",
    "B. It encoded biological rules manually  \n",
    "C. It iteratively learned protein folding geometry through feedback  \n",
    "D. It generated new amino acids\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** RL allowed AlphaFold to refine folding predictions by receiving reward-based feedback on predicted structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17\n",
    "\n",
    "What distinguishes \"reasoning machines\" from earlier language models?\n",
    "\n",
    "A. They use larger training datasets  \n",
    "B. They no longer hallucinate facts  \n",
    "C. They can internally generalize logic, validate hypotheses, and create reproducible outputs  \n",
    "D. They require no training whatsoever\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** True reasoning systems can validate and hypothesize internally, unlike models that only predict next tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18\n",
    "\n",
    "What is the main advantage of neural networks for unstructured data?\n",
    "\n",
    "A. They can effectively handle images, text, and audio  \n",
    "B. They require less computational power  \n",
    "C. They are easier to implement than other algorithms  \n",
    "D. They always provide more accurate results\n",
    "\n",
    "**Answer: A**\n",
    "\n",
    "**Rationale:** Deep architectures learn hierarchical features automatically from unstructured modalities, reducing manual feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "\n",
    "In supervised learning, what does the residual ($\\hat{y} - y$) encompass?\n",
    "\n",
    "A. Only the model's systematic error (bias)  \n",
    "B. Only the irreducible noise in data  \n",
    "C. The total error (model error + noise) on that example  \n",
    "D. The gradient used for weight updates\n",
    "\n",
    "**Answer: C**\n",
    "\n",
    "**Rationale:** The residual is the observed difference. It can be decomposed into bias, variance, and irreducible noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20\n",
    "\n",
    "According to the bias-variance decomposition, what is the irreducible noise ($\\sigma^2$)?\n",
    "\n",
    "A. The model's training error  \n",
    "B. The variance of predictions across datasets  \n",
    "C. The squared bias of the estimator  \n",
    "D. The error component due to inherent randomness in data\n",
    "\n",
    "**Answer: D**\n",
    "\n",
    "**Rationale:** $\\sigma^2$ represents the irreducible error from random factors in the data generation process that no model can eliminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quiz Summary\n",
    "\n",
    "This quiz covers fundamental concepts in AI and Machine Learning including:\n",
    "\n",
    "- No Free Lunch Theorem\n",
    "- AI vs Machine Learning relationship\n",
    "- Loss functions and optimization\n",
    "- Neural network fundamentals\n",
    "- Activation functions\n",
    "- Universal Approximation Theorem\n",
    "- Bias-variance decomposition\n",
    "- Recent advances in AI (AlphaFold, reasoning machines)\n",
    "\n",
    "**Total Questions: 20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add code here for quiz analysis, scoring, or interactive features\n",
    "# For example:\n",
    "\n",
    "# Quiz answers for reference\n",
    "answers = ['C', 'A', 'C', 'C', 'A', 'C', 'C', 'C', 'B', 'C', \n",
    "           'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'C', 'D']\n",
    "\n",
    "print(f\"Quiz contains {len(answers)} questions\")\n",
    "print(f\"Answer key: {answers}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
